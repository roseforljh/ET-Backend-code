import  logging
import  re
from  typing  import  Dict,  Any,  AsyncGenerator

from  ...models.api_models  import  AppStreamEventPy
from  ...utils.helpers  import  get_current_time_iso
from  .flush  import  MarkdownBlockDetector  as  _FlushDetector
from  .format_fixer  import  fix_markdown_format

logger  =  logging.getLogger("EzTalkProxy.StreamProcessors")

def get_strategy_for_text(text: str) -> tuple[Any, str]:
    """
    è¿”å›æ— æ“ä½œç­–ç•¥ï¼Œä¿æŒAIè¾“å‡ºåŸæ ·ã€‚
    Always returns (None, "general").
    """
    return None, "general"
 
def lightweight_cleanup(text: str, is_streaming: bool = True) -> str:
    """
    æœ€å°åŒ–æ¸…ç†ï¼šä»…ç»Ÿä¸€æ¢è¡Œç¬¦ï¼Œä¿æŒAIåŸå§‹è¾“å‡ºã€‚
    
    å‚æ•°ï¼š
        text: å¾…æ¸…ç†çš„æ–‡æœ¬
        is_streaming: æ˜¯å¦ä¸ºæµå¼è¾“å‡ºæ¨¡å¼ï¼ˆé»˜è®¤Trueï¼‰
    
    æ¸…ç†å†…å®¹ï¼š
    - ç»Ÿä¸€æ¢è¡Œç¬¦æ ¼å¼ï¼ˆ\r\n -> \nï¼‰
    """
    if not text:
        return text
    
    # ä»…ç»Ÿä¸€æ¢è¡Œç¬¦æ ¼å¼ï¼Œå…¶ä½™ä¿æŒåŸæ ·
    text = text.replace('\r\n', '\n').replace('\r', '\n')
    
    return text

# --- Streaming-safe helpers for code fences ---
_fence_line_re = re.compile(r'^(\s*)([`~]{3,})(.*)$')

def selective_cleanup_with_code_fence(text: str, state: Dict[str, Any]) -> str:
    """
    ç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä¸åšä»»ä½•æ¸…ç†ã€‚
    ä¿æŒå‡½æ•°ç­¾åä»¥å…¼å®¹ç°æœ‰ä»£ç ã€‚
    """
    return text

def _is_meaningful(chunk: str) -> bool:
    """
    åˆ¤å®šå¢é‡æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼šè¿‡æ»¤åªåŒ…å«ç©ºç™½å­—ç¬¦ï¼ˆç©ºæ ¼/åˆ¶è¡¨ç¬¦/æ¢è¡Œï¼‰çš„å—ã€‚
    """
    return bool(chunk) and bool(chunk.strip())

def _ensure_code_blocks_closed(text: str) -> str:
    """
    ç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä¸åšä»£ç å—é—­åˆä¿®å¤ã€‚
    ä¿æŒå‡½æ•°ç­¾åä»¥å…¼å®¹ç°æœ‰ä»£ç ã€‚
    """
    return text

async def process_openai_like_sse_stream(
    parsed_sse_data: Dict[str, Any],
    current_processing_state: Dict[str, Any],
    request_id: str,
    request_data = None
) -> AsyncGenerator[Dict[str, Any], None]:
    log_prefix = f"RID-{request_id}"
    
    state = current_processing_state
    state.setdefault("had_any_reasoning", False)
    state.setdefault("reasoning_finish_event_sent", False)
    # åˆ†ç¦»æ­£æ–‡ä¸æ€è€ƒçš„ç´¯ç§¯ï¼Œé¿å…æœ€ç»ˆæ¸…ç†æŠŠæ€è€ƒæ··å…¥æ­£æ–‡
    state.setdefault("accumulated_content", "")
    state.setdefault("accumulated_reasoning", "")
    state.setdefault("detected_type", "general")  # å­˜å‚¨æ£€æµ‹åˆ°çš„å†…å®¹ç±»å‹
    # Track fenced code block state across streaming chunks
    state.setdefault("code_fence", {"in": False, "marker": ""})

    for choice in parsed_sse_data.get('choices', []):
        delta = choice.get('delta', {})
        content_chunk = delta.get("content")
        reasoning_chunk = delta.get("reasoning_content") or delta.get("reasoning") or delta.get("thinking") or delta.get("thoughts")
        finish_reason = choice.get("finish_reason")

        if reasoning_chunk:
            # ğŸ” [STREAM_DEBUG] è®°å½•reasoningäº‹ä»¶å‘é€
            logger.info(f"[STREAM_DEBUG] {log_prefix} âœ… SENDING reasoning event: len={len(reasoning_chunk)}")
            yield {"type": "reasoning", "text": str(reasoning_chunk), "timestamp": get_current_time_iso()}
            state["had_any_reasoning"] = True
            # åˆ†å¼€ç´¯ç§¯æ€è€ƒæ–‡æœ¬ï¼Œç»ä¸æ··å…¥æ­£æ–‡æœ€ç»ˆæ¸…ç†
            state["accumulated_reasoning"] = str(state.get("accumulated_reasoning", "")) + str(reasoning_chunk)

        # ä»…å¯¹æ­£æ–‡è¿›è¡Œæ¸…ç†ä¸ç´¯ç§¯ï¼Œç”¨äºç±»å‹æ£€æµ‹ä¸åˆ·æ–°åˆ¤å®š
        if _is_meaningful(content_chunk):
            # ğŸ¯ Markdown format fix (safe, backend)
            cleaned_for_accumulation = fix_markdown_format(str(content_chunk), aggressive=False)
            if _is_meaningful(cleaned_for_accumulation):
                state["accumulated_content"] += cleaned_for_accumulation

            # ç»Ÿä¸€ç­–ç•¥ï¼šç«‹å³å‘é€æ‰€æœ‰å†…å®¹
            logger.info(f"[STREAM_DEBUG] {log_prefix} Immediate flush, chunk_len={len(cleaned_for_accumulation)}")

            if state["had_any_reasoning"] and not state["reasoning_finish_event_sent"]:
                # å¦‚æœæˆ‘ä»¬å·²ç»å¤„ç†äº† reasoningï¼Œå¹¶ä¸”ç°åœ¨æœ‰äº†å®é™…å†…å®¹ï¼Œé‚£ä¹ˆ reasoning é˜¶æ®µç»“æŸ
                if content_chunk:
                    logger.info(f"[STREAM_DEBUG] {log_prefix} Sending reasoning_finish event")
                    yield {"type": "reasoning_finish", "timestamp": get_current_time_iso()}
                    state["reasoning_finish_event_sent"] = True

            # åŠ¨æ€æ£€æµ‹ output_type å¹¶å­˜å‚¨ï¼ˆä»…åŸºäºæ­£æ–‡ï¼‰
            _, detected_type = get_strategy_for_text(state["accumulated_content"])
            state["detected_type"] = detected_type

            # å‘é€æ­£æ–‡å¢é‡ï¼ˆå·²æ¸…ç†è¿‡ï¼Œç›´æ¥å‘é€ï¼Œé¿å…äºŒæ¬¡æ¸…ç†ï¼‰
            if content_chunk and _is_meaningful(cleaned_for_accumulation):
                # ğŸ” [STREAM_DEBUG] è®°å½•contentäº‹ä»¶å‘é€
                logger.info(f"[STREAM_DEBUG] {log_prefix} âœ… SENDING content event: len={len(cleaned_for_accumulation)}, type={detected_type}, preview='{cleaned_for_accumulation[:50]}'")
                yield {
                    "type": "content",
                    "text": cleaned_for_accumulation,  # ğŸ¯ ä¿®å¤ï¼šä½¿ç”¨å·²æ¸…ç†çš„å†…å®¹ï¼Œé¿å…é‡å¤è°ƒç”¨lightweight_cleanup
                    "output_type": detected_type,
                    "timestamp": get_current_time_iso()
                }

        if finish_reason:
            if state["had_any_reasoning"] and not state["reasoning_finish_event_sent"]:
                yield {"type": "reasoning_finish", "timestamp": get_current_time_iso()}
                state["reasoning_finish_event_sent"] = True

            # ç»“æŸæ—¶å‘é€ä¸€æ¬¡å…¨é‡ä¿®å¤åçš„å†…å®¹ï¼Œè§£å†³è¡¨æ ¼åˆ†éš”çº¿è¢«æ‹†åˆ†å¯¼è‡´æ— æ³•æ¸²æŸ“çš„é—®é¢˜
            accumulated = state.get("accumulated_content", "")
            if accumulated:
                logger.info(f"{log_prefix} Stream ending with accumulated content length: {len(accumulated)} chars")
                try:
                    # ä»…ç”¨äºè¯Šæ–­ï¼šè®¡ç®—æœ€ç»ˆä¿®å¤ä½†ä¸ä¸‹å‘åˆ°å®¢æˆ·ç«¯ï¼Œæœ€ç»ˆä¿®å¤ç»Ÿä¸€äº¤ç”±å‰ç«¯å®Œæˆ
                    _ = fix_markdown_format(accumulated, aggressive=True)
                except Exception as e:
                    logger.exception(f"{log_prefix} Failed to finalize markdown fix (diagnostic only): {e}")
            
            yield {"type": "finish", "reason": finish_reason, "timestamp": get_current_time_iso()}