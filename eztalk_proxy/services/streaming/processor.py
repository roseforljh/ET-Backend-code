import  logging
import  re
import  orjson
from  typing  import  Dict,  Any,  AsyncGenerator

from  ...models.api_models  import  AppStreamEventPy
from  ...utils.helpers  import  get_current_time_iso
from  .flush  import  MarkdownBlockDetector  as  _FlushDetector
# format_fixer removed per requirement

logger  =  logging.getLogger("EzTalkProxy.StreamProcessors")

def get_strategy_for_text(text: str) -> tuple[Any, str]:
    """
    è¿”å›æ— æ“ä½œç­–ç•¥ï¼Œä¿æŒAIè¾“å‡ºåŸæ ·ã€‚
    Always returns (None, "general").
    """
    return None, "general"
 
def lightweight_cleanup(text: str, is_streaming: bool = True) -> str:
    """
    æœ€å°åŒ–æ¸…ç†ï¼šä»…ç»Ÿä¸€æ¢è¡Œç¬¦ï¼Œä¿æŒAIåŸå§‹è¾“å‡ºã€‚
    
    å‚æ•°ï¼š
        text: å¾…æ¸…ç†çš„æ–‡æœ¬
        is_streaming: æ˜¯å¦ä¸ºæµå¼è¾“å‡ºæ¨¡å¼ï¼ˆé»˜è®¤Trueï¼‰
    
    æ¸…ç†å†…å®¹ï¼š
    - ç»Ÿä¸€æ¢è¡Œç¬¦æ ¼å¼ï¼ˆ\r\n -> \nï¼‰
    """
    if not text:
        return text
    
    # ä»…ç»Ÿä¸€æ¢è¡Œç¬¦æ ¼å¼ï¼Œå…¶ä½™ä¿æŒåŸæ ·
    text = text.replace('\r\n', '\n').replace('\r', '\n')
    
    return text

# --- Streaming-safe helpers for code fences ---
_fence_line_re = re.compile(r'^(\s*)([`~]{3,})(.*)$')

def selective_cleanup_with_code_fence(text: str, state: Dict[str, Any]) -> str:
    """
    ç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä¸åšä»»ä½•æ¸…ç†ã€‚
    ä¿æŒå‡½æ•°ç­¾åä»¥å…¼å®¹ç°æœ‰ä»£ç ã€‚
    """
    return text

def _is_meaningful(chunk: str) -> bool:
    """
    åˆ¤å®šå¢é‡æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼šè¿‡æ»¤åªåŒ…å«ç©ºç™½å­—ç¬¦ï¼ˆç©ºæ ¼/åˆ¶è¡¨ç¬¦/æ¢è¡Œï¼‰çš„å—ã€‚
    """
    return bool(chunk) and bool(chunk.strip())

def _ensure_code_blocks_closed(text: str) -> str:
    """
    ç›´æ¥è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä¸åšä»£ç å—é—­åˆä¿®å¤ã€‚
    ä¿æŒå‡½æ•°ç­¾åä»¥å…¼å®¹ç°æœ‰ä»£ç ã€‚
    """
    return text

def _try_parse_openai_gemini_code_events(content_chunk: Any) -> tuple[bool, list[Dict[str, Any]]]:
    """
    è§£æ OpenAI å…¼å®¹æµä¸­çš„ Gemini ä»£ç æ‰§è¡Œç‰¹æ®Šå¢é‡ã€‚
    - content å¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²ï¼ŒåŒ…å« executableCode æˆ– codeExecutionResult
    - è¿”å›: (æ˜¯å¦å·²å¤„ç†, äº‹ä»¶åˆ—è¡¨[dict])
    """
    events: list[Dict[str, Any]] = []
    try:
        # ç»Ÿä¸€è½¬æ–‡æœ¬
        if isinstance(content_chunk, (bytes, bytearray)):
            text = content_chunk.decode("utf-8", "ignore")
        else:
            text = str(content_chunk)
        s = (text or "").strip()
        # å¿…é¡»å½¢å¦‚ JSON
        if not s or not (s.startswith("{") or s.startswith("[")):
            return False, []
        data = orjson.loads(s)

        def handle_obj(obj: Any) -> None:
            if not isinstance(obj, dict):
                return
            # å¯æ‰§è¡Œä»£ç 
            if "executableCode" in obj:
                ec = obj.get("executableCode") or {}
                code = ec.get("code") or ""
                lang = ec.get("language") or "python"
                if code:
                    events.append({
                        "type": "code_executable",
                        "executable_code": code,
                        "code_language": lang
                    })
            # æ‰§è¡Œç»“æœ
            if "codeExecutionResult" in obj:
                res = obj.get("codeExecutionResult") or {}
                output = res.get("output") or ""
                outcome = res.get("outcome") or res.get("status") or ""
                if str(outcome).upper() in ("OUTCOME_OK", "SUCCESS", "OK"):
                    outcome_norm = "success"
                elif outcome:
                    outcome_norm = "error"
                else:
                    outcome_norm = "success" if output else None
                ev: Dict[str, Any] = {
                    "type": "code_execution_result",
                    "code_execution_output": output
                }
                if outcome_norm:
                    ev["code_execution_outcome"] = outcome_norm
                events.append(ev)

        if isinstance(data, dict):
            handle_obj(data)
        elif isinstance(data, list):
            for item in data:
                handle_obj(item)

        return (len(events) > 0), events
    except Exception:
        # ä»»æ„è§£æå¤±è´¥è§†ä¸ºéä»£ç äº‹ä»¶
        return False, []

async def process_openai_like_sse_stream(
    parsed_sse_data: Dict[str, Any],
    current_processing_state: Dict[str, Any],
    request_id: str,
    request_data = None
) -> AsyncGenerator[Dict[str, Any], None]:
    log_prefix = f"RID-{request_id}"
    
    state = current_processing_state
    state.setdefault("had_any_reasoning", False)
    state.setdefault("reasoning_finish_event_sent", False)
    # åˆ†ç¦»æ­£æ–‡ä¸æ€è€ƒçš„ç´¯ç§¯ï¼Œé¿å…æœ€ç»ˆæ¸…ç†æŠŠæ€è€ƒæ··å…¥æ­£æ–‡
    state.setdefault("accumulated_content", "")
    state.setdefault("accumulated_reasoning", "")
    state.setdefault("detected_type", "general")  # å­˜å‚¨æ£€æµ‹åˆ°çš„å†…å®¹ç±»å‹
    # Track fenced code block state across streaming chunks
    state.setdefault("code_fence", {"in": False, "marker": ""})

    for choice in parsed_sse_data.get('choices', []):
        delta = choice.get('delta', {})
        content_chunk = delta.get("content")
        reasoning_chunk = delta.get("reasoning_content") or delta.get("reasoning") or delta.get("thinking") or delta.get("thoughts")
        finish_reason = choice.get("finish_reason")

        if reasoning_chunk:
            # ğŸ” [STREAM_DEBUG] è®°å½•reasoningäº‹ä»¶å‘é€
            logger.info(f"[STREAM_DEBUG] {log_prefix} âœ… SENDING reasoning event: len={len(reasoning_chunk)}")
            yield {"type": "reasoning", "text": str(reasoning_chunk), "timestamp": get_current_time_iso()}
            state["had_any_reasoning"] = True
            # åˆ†å¼€ç´¯ç§¯æ€è€ƒæ–‡æœ¬ï¼Œç»ä¸æ··å…¥æ­£æ–‡æœ€ç»ˆæ¸…ç†
            state["accumulated_reasoning"] = str(state.get("accumulated_reasoning", "")) + str(reasoning_chunk)

        # å…ˆå°è¯•è§£æ Gemini çš„ä»£ç æ‰§è¡Œç‰¹æ®Šäº‹ä»¶ï¼ˆOpenAI å…¼å®¹æµï¼‰
        if _is_meaningful(content_chunk):
            handled_code, code_events = _try_parse_openai_gemini_code_events(content_chunk)
            if handled_code and code_events:
                for ev in code_events:
                    ev["timestamp"] = get_current_time_iso()
                    logger.info(f"[STREAM_DEBUG] {log_prefix} âœ… SENDING code event: type={ev.get('type')}, len_output={len(ev.get('code_execution_output','') or ev.get('executable_code',''))}")
                    yield ev
                # è§£æåˆ°ä»£ç äº‹ä»¶åˆ™ä¸æŒ‰æ™®é€šæ–‡æœ¬é‡å¤å‘é€
                content_chunk = None

        # ä»…å¯¹æ­£æ–‡è¿›è¡Œæ¸…ç†ä¸ç´¯ç§¯ï¼Œç”¨äºç±»å‹æ£€æµ‹ä¸åˆ·æ–°åˆ¤å®š
        if _is_meaningful(content_chunk):
            # ğŸ¯ åœç”¨åç«¯é¢„å¤„ç†ï¼šç›´æ¥é€ä¼ åŸå§‹å¢é‡
            cleaned_for_accumulation = str(content_chunk)
            if _is_meaningful(cleaned_for_accumulation):
                state["accumulated_content"] += cleaned_for_accumulation

            # ç»Ÿä¸€ç­–ç•¥ï¼šç«‹å³å‘é€æ‰€æœ‰å†…å®¹
            logger.info(f"[STREAM_DEBUG] {log_prefix} Immediate flush, chunk_len={len(cleaned_for_accumulation)}")

            if state["had_any_reasoning"] and not state["reasoning_finish_event_sent"]:
                # å¦‚æœæˆ‘ä»¬å·²ç»å¤„ç†äº† reasoningï¼Œå¹¶ä¸”ç°åœ¨æœ‰äº†å®é™…å†…å®¹ï¼Œé‚£ä¹ˆ reasoning é˜¶æ®µç»“æŸ
                if content_chunk:
                    logger.info(f"[STREAM_DEBUG] {log_prefix} Sending reasoning_finish event")
                    yield {"type": "reasoning_finish", "timestamp": get_current_time_iso()}
                    state["reasoning_finish_event_sent"] = True

            # åŠ¨æ€æ£€æµ‹ output_type å¹¶å­˜å‚¨ï¼ˆä»…åŸºäºæ­£æ–‡ï¼‰
            _, detected_type = get_strategy_for_text(state["accumulated_content"])
            state["detected_type"] = detected_type

            # å‘é€æ­£æ–‡å¢é‡ï¼ˆå·²æ¸…ç†è¿‡ï¼Œç›´æ¥å‘é€ï¼Œé¿å…äºŒæ¬¡æ¸…ç†ï¼‰
            if content_chunk and _is_meaningful(cleaned_for_accumulation):
                # ğŸ” [STREAM_DEBUG] è®°å½•contentäº‹ä»¶å‘é€
                logger.info(f"[STREAM_DEBUG] {log_prefix} âœ… SENDING content event: len={len(cleaned_for_accumulation)}, type={detected_type}, preview='{cleaned_for_accumulation[:50]}'")
                yield {
                    "type": "content",
                    "text": cleaned_for_accumulation,  # ğŸ¯ ä¿®å¤ï¼šä½¿ç”¨å·²æ¸…ç†çš„å†…å®¹ï¼Œé¿å…é‡å¤è°ƒç”¨lightweight_cleanup
                    "output_type": detected_type,
                    "timestamp": get_current_time_iso()
                }

        if finish_reason:
            if state["had_any_reasoning"] and not state["reasoning_finish_event_sent"]:
                yield {"type": "reasoning_finish", "timestamp": get_current_time_iso()}
                state["reasoning_finish_event_sent"] = True

            # åœç”¨è¯Šæ–­æ€§æœ€ç»ˆä¿®å¤ï¼šä»…è®°å½•é•¿åº¦ä¿¡æ¯ï¼Œç›´æ¥ç»“æŸ
            accumulated = state.get("accumulated_content", "")
            if accumulated:
                logger.info(f"{log_prefix} Stream ending with accumulated content length: {len(accumulated)} chars")
            
            yield {"type": "finish", "reason": finish_reason, "timestamp": get_current_time_iso()}