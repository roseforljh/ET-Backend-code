import logging
import uuid
from typing import List, Optional
from urllib.parse import urlparse

from fastapi import APIRouter, Depends, Request, HTTPException, UploadFile
from fastapi.responses import StreamingResponse
import httpx
import orjson

from ..models.api_models import ChatRequestModel
from ..core.config import MAX_DOCUMENT_UPLOAD_SIZE_MB
from . import gemini, openai

logger = logging.getLogger("EzTalkProxy.Routers.Chat")
router = APIRouter()

def mask_api_key_for_log(api_key: Optional[str]) -> str:
    if not api_key:
        return "(empty)"
    head = api_key[:4]
    tail = api_key[-4:] if len(api_key) > 8 else "****"
    return f"{head}...{tail} (len={len(api_key)})"

def is_google_official_api(api_address: str) -> bool:
    """
    åˆ¤æ–­APIåœ°å€æ˜¯å¦ä¸ºGoogleå®˜æ–¹åœ°å€
    Googleå®˜æ–¹Gemini APIåœ°å€é€šå¸¸åŒ…å«ï¼š
    - generativelanguage.googleapis.com
    - aiplatform.googleapis.com
    - googleapis.com (é€šç”¨Google APIåŸŸå)
    """
    if not api_address:
        return False
    
    try:
        parsed_url = urlparse(api_address)
        domain = parsed_url.netloc.lower()
        
        # Googleå®˜æ–¹APIåŸŸååˆ—è¡¨
        google_domains = [
            'generativelanguage.googleapis.com',
            'aiplatform.googleapis.com',
            'googleapis.com',
            'ai.google.dev'  # Google AI Studio API
        ]
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºGoogleå®˜æ–¹åŸŸåæˆ–å…¶å­åŸŸå
        for google_domain in google_domains:
            if domain == google_domain or domain.endswith('.' + google_domain):
                return True
                
        return False
    except Exception as e:
        logger.warning(f"Failed to parse API address '{api_address}': {e}")
        return False

async def get_http_client(request: Request) -> httpx.AsyncClient:
    client = getattr(request.app.state, "http_client", None)
    if client is None or (hasattr(client, 'is_closed') and client.is_closed):
        logger.error("HTTP client not available or closed in app.state.")
        raise HTTPException(status_code=503, detail="Service unavailable: HTTP client not initialized or closed.")
    return client

async def extract_chat_request_from_form(request: Request) -> tuple[str, List[UploadFile]]:
    """
    ä» multipart/form-data è¯·æ±‚ä¸­æå–èŠå¤©è¯·æ±‚æ•°æ®ï¼Œå¹¶æ˜¾å¼æ”¾å®½å• part é™åˆ¶ã€‚
    """
    try:
        # ç»Ÿä¸€å°†å• part ä¸Šé™æå‡åˆ° 50MBï¼ˆæˆ–åç«¯é…ç½®çš„æ›´å¤§å€¼ï¼‰
        limit_mb = max(50, int(MAX_DOCUMENT_UPLOAD_SIZE_MB or 0))
        form = await request.form(max_files=200, max_fields=2000, max_part_size=limit_mb * 1024 * 1024)

        chat_request_json_str = None
        uploaded_files: List[UploadFile] = []

        # æ ‡å‡†å­—æ®µ
        if "chat_request_json" in form:
            chat_request_json_str = form["chat_request_json"]

        # å…œåº•ï¼šéå†å­—ç¬¦ä¸²å­—æ®µå¯»æ‰¾ JSON
        if not chat_request_json_str:
            for key, value in form.items():
                if isinstance(value, str):
                    try:
                        potential = orjson.loads(value)
                        if isinstance(potential, dict) and "messages" in potential and "model" in potential:
                            chat_request_json_str = value
                            logger.info(f"Found chat_request_json in form field '{key}' (fallback method)")
                            break
                    except (orjson.JSONDecodeError, TypeError):
                        continue

        # æ”¶é›†ä¸Šä¼ æ–‡ä»¶
        for _, value in form.items():
            if hasattr(value, "filename") and hasattr(value, "file"):
                uploaded_files.append(value)  # type: ignore[arg-type]

        if not chat_request_json_str:
            raise HTTPException(status_code=400, detail="Missing 'chat_request_json' field in form data")

        return chat_request_json_str, uploaded_files

    except Exception as e:
        logger.error(f"Error extracting chat request from form: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=f"Failed to parse multipart form data: {e}")

def decide_chat_channel(chat_input: ChatRequestModel) -> tuple[str, str]:
    """
    å†³ç­–æ–‡æœ¬èŠå¤©æ‰€ç”¨æ¸ é“ï¼š
    - ä¼˜å…ˆä¾æ® provider å…³é”®è¯
    - æ¬¡é€‰ä¾æ® model æ˜¯å¦åŒ…å« 'gemini'
    - æœ€åä¾æ® apiAddress æ˜¯å¦ä¸º Google å®˜æ–¹åŸŸå
    è¿”å› (channel, reason)ï¼Œchannel âˆˆ {'gemini','openai'}
    reason âˆˆ {'provider','model','domain','fallback'}
    """
    provider_lower = (chat_input.provider or "").lower()
    gemini_keys = ["gemini", "google", "vertex", "aistudio", "google-gemini"]
    openai_keys = ["openai", "azure", "oai", "gpt", "openai-compatible", "openai_compatible"]

    if any(k in provider_lower for k in gemini_keys):
        return "gemini", "provider"
    if any(k in provider_lower for k in openai_keys):
        return "openai", "provider"

    model_lower = (chat_input.model or "").lower()
    if "gemini" in model_lower:
        return "gemini", "model"

    if is_google_official_api(chat_input.api_address or ""):
        return "gemini", "domain"

    return "openai", "fallback"

@router.post("/chat", response_class=StreamingResponse, summary="AIèŠå¤©å®Œæˆä»£ç†", tags=["AI Proxy"])
async def chat_proxy_entrypoint(
    fastapi_request_obj: Request,
    http_client: httpx.AsyncClient = Depends(get_http_client),
):
    request_id = str(uuid.uuid4())
    log_prefix = f"RID-{request_id}"

    # ç»Ÿä¸€åœ¨å¤„ç†å™¨å†…éƒ¨ä»¥æ”¾å®½çš„ max_part_size è§£æè¡¨å•ï¼Œé¿å… 1MB é»˜è®¤é™åˆ¶
    chat_request_json_str, uploaded_documents = await extract_chat_request_from_form(fastapi_request_obj)

    logger.info(f"{log_prefix}: Received /chat request with {len(uploaded_documents)} documents.")

    try:
        chat_input_data = orjson.loads(chat_request_json_str)
        chat_input = ChatRequestModel(**chat_input_data)
        logger.info(f"{log_prefix}: Parsed ChatRequestModel for provider '{chat_input.provider}' and model '{chat_input.model}'.")
        
        # ğŸ†• æ£€æµ‹å¹¶æ³¨å…¥"é»˜è®¤"å¹³å°çš„é…ç½®ï¼ˆæ–‡æœ¬æ¨¡å¼ï¼‰
        provider_lower = (chat_input.provider or "").lower().strip()
        is_default_provider = provider_lower in ["é»˜è®¤", "default"]
        
        if is_default_provider:
            from ..core.config import DEFAULT_TEXT_API_URL, DEFAULT_TEXT_API_KEY, DEFAULT_TEXT_MODELS
            
            # éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨å…è®¸çš„é»˜è®¤æ¨¡å‹åˆ—è¡¨ä¸­
            if chat_input.model not in DEFAULT_TEXT_MODELS:
                logger.warning(f"{log_prefix}: Model '{chat_input.model}' not in DEFAULT_TEXT_MODELS list, but allowing it for default provider")
            
            # æ³¨å…¥åç«¯é…ç½®çš„ API åœ°å€å’Œå¯†é’¥
            if not chat_input.api_address or chat_input.api_address.strip() == "":
                chat_input.api_address = DEFAULT_TEXT_API_URL
                logger.info(f"{log_prefix}: Injected DEFAULT_TEXT_API_URL for default provider")
            
            if not chat_input.api_key or chat_input.api_key.strip() == "":
                chat_input.api_key = DEFAULT_TEXT_API_KEY
                logger.info(f"{log_prefix}: Injected DEFAULT_TEXT_API_KEY for default provider")
            
            if not chat_input.api_key:
                logger.error(f"{log_prefix}: No DEFAULT_TEXT_API_KEY configured in environment for default provider")
                raise HTTPException(
                    status_code=500,
                    detail="Default text API key not configured on server. Please contact administrator."
                )
        
        try:
            masked = mask_api_key_for_log(getattr(chat_input, "api_key", None))
            logger.info(f"{log_prefix}: API key fingerprint: {masked}; apiAddress='{chat_input.api_address}'")
        except Exception as _e:
            logger.debug(f"{log_prefix}: Failed to log api key fingerprint safely: {_e}")
    except (orjson.JSONDecodeError, TypeError, ValueError) as e:
        logger.error(f"{log_prefix}: Failed to parse or validate chat request JSON: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=f"Invalid chat request data: {e}")

    # ğŸ†• é»˜è®¤å¹³å°å¼ºåˆ¶ä½¿ç”¨ OpenAI å…¼å®¹å¤„ç†å™¨ï¼ˆå› ä¸ºé»˜è®¤APIæ˜¯èšåˆå•†ï¼Œä¸æ˜¯Googleå®˜æ–¹ï¼‰
    if is_default_provider:
        channel = "openai"
        reason = "default_provider"
        logger.info(f"{log_prefix}: Forcing OpenAI-compatible channel for default provider")
    else:
        # ä½¿ç”¨æ–°ç‰ˆåˆ†å‘ï¼šchannel ä¼˜å…ˆï¼ˆå®ç°"æ–‡æœ¬æ¨¡å¼ Gemini å¯èµ°èšåˆå•†é“¾è·¯"ï¼‰
        channel, reason = decide_chat_channel_v2(chat_input)
    
    logger.info(f"{log_prefix}: Channel decided (v2) => {channel} (reason={reason}); "
                f"provider='{chat_input.provider}', model='{chat_input.model}', api='{chat_input.api_address}', channel_field='{getattr(chat_input, 'channel', None)}'.")

    if channel == "gemini":
        # ä»…å½“ç¡®è®¤ä¸º Gemini å®˜æ–¹ç›´è¿æ—¶æ‰è¿›å…¥ gemini å¤„ç†å™¨ï¼›ä¸å†å¼ºåˆ¶è¦†ç›–ä¸ºå®˜æ–¹åœ°å€
        return await gemini.handle_gemini_request(
            gemini_chat_input=chat_input,
            uploaded_files=uploaded_documents,
            fastapi_request_obj=fastapi_request_obj,
            http_client=http_client,
            request_id=request_id,
        )
    else:
        # å…¶ä½™ï¼ˆåŒ…æ‹¬ Gemini + èšåˆå•†ï¼‰ç»Ÿä¸€èµ° OpenAI å…¼å®¹åˆ†æ”¯ï¼ˆä¸å›¾åƒæ¨¡å¼è¡Œä¸ºä¿æŒä¸€è‡´ï¼‰
        return await openai.handle_openai_compatible_request(
            chat_input=chat_input,
            uploaded_documents=uploaded_documents,
            fastapi_request_obj=fastapi_request_obj,
            http_client=http_client,
            request_id=request_id,
        )
def decide_chat_channel_v2(chat_input: ChatRequestModel) -> tuple[str, str]:
    """
    æ–‡æœ¬æ¨¡å¼åˆ†å‘ï¼ˆchannel ä¼˜å…ˆï¼‰ï¼š
    - è‹¥ channel æ˜ç¡®ä¸º OpenAI å…¼å®¹ï¼ˆå«â€œopenaiâ€ã€â€œå…¼å®¹â€ã€â€œcompatibleâ€ã€â€œoaiâ€ã€â€œazureâ€ç­‰ï¼‰ï¼Œç›´æ¥èµ° openai
    - è‹¥ channel æ˜ç¡®ä¸º Gemini å®˜æ–¹ï¼ˆå«â€œgeminiâ€ã€â€œgoogleâ€ã€â€œaistudioâ€ã€â€œai studioâ€ã€â€œå®˜æ–¹â€ç­‰ï¼‰ï¼š
        * è‹¥ apiAddress æ˜¯ Google å®˜æ–¹åŸŸåæˆ–æœªæä¾› â†’ gemini
        * å¦åˆ™ï¼ˆåœ°å€çœ‹èµ·æ¥æ˜¯èšåˆå•†ï¼‰â†’ openaiï¼ˆé¿å…æŠŠèšåˆå•†å¼ºåˆ¶æ”¹æˆç›´è¿ Googleï¼‰
    - å¦‚ channel æœªæ˜ç¡®ï¼šæŒ‰ provider â†’ model â†’ åŸŸåå…œåº•
    è¿”å› (channel, reason)ï¼Œchannel âˆˆ {'gemini','openai'}
    """
    channel_lower = (getattr(chat_input, "channel", None) or "").lower()
    provider_lower = (chat_input.provider or "").lower()
    model_lower = (chat_input.model or "").lower()
    api_addr = (chat_input.api_address or "")

    # 1) channel æ˜ç¡®ä¼˜å…ˆ
    if channel_lower:
        # OpenAI å…¼å®¹é€šé“å…³é”®è¯
        openai_keys = ["openai", "å…¼å®¹", "compatible", "oai", "azure"]
        if any(k in channel_lower for k in openai_keys):
            return "openai", "channel"

        # Gemini å®˜æ–¹é€šé“å…³é”®è¯ï¼ˆæŒ‰ä½ çš„è¦æ±‚ï¼šåªè¦ channel è¡¨ç¤º Geminiï¼Œå°±è§†ä¸º Gemini è¯­ä¹‰ï¼Œä¸å†å› åœ°å€è€Œå›é€€åˆ° OpenAI å…¼å®¹ï¼‰
        gemini_channel_keys = ["gemini", "google", "aistudio", "ai studio", "å®˜æ–¹"]
        if any(k in channel_lower for k in gemini_channel_keys):
            return "gemini", "channel"

    # 2) provider æ¨æ–­
    # å¸¸è§èšåˆ/ä»£ç†å…³é”®è¯ï¼ˆå°½é‡çª„åŒ¹é…ï¼Œé¿å…è¯¯æ€ï¼‰
    provider_is_aggregator = any(
        key in provider_lower
        for key in ["asb", "abs", "openrouter", "router", "done", "hub"]
    )
    if provider_is_aggregator:
        return "openai", "provider_agg"

    gemini_provider_keys = ["gemini", "google", "vertex", "aistudio", "google-gemini"]
    if any(k in provider_lower for k in gemini_provider_keys):
        return "gemini", "provider"

    # 3) model æ¨æ–­
    if "gemini" in model_lower:
        return "gemini", "model"

    # 4) åŸŸåå…œåº•
    if is_google_official_api(api_addr):
        return "gemini", "domain"

    return "openai", "fallback"